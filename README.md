# TinyLLM
# ðŸ§  TinyLLM

**TinyLLM** is a minimalist character-level Transformer language model implemented in Rust. It's built as a learning project to understand how large language models (LLMs) work under the hood â€” from tokenization and training to inference.

> ðŸš€ Inspired by projects like [nanoGPT](https://github.com/karpathy/nanoGPT), but written in idiomatic Rust with a focus on clarity and control.

---

## ðŸ“¦ Features

- âœ… Pure Rust implementation â€” no Python or external ML frameworks
- âœ… Character-level tokenizer
- âœ… Transformer architecture with self-attention
- âœ… Adam optimizer with weight decay and bias correction
- âœ… Checkpointing for training state
- âœ… Simple sampling/generation loop
- âœ… Grad norm + loss tracking
- âœ… Tests for core components

---

## ðŸš€ Getting Started

### 1. Clone the repo
```bash
git clone https://github.com/valicitor/tinyllm.git
cd tinyllm
```
